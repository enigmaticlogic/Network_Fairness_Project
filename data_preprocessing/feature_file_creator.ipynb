{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from collections import OrderedDict \n",
    "from operator import itemgetter\n",
    "import os\n",
    "\n",
    "def read_nodes(node_file, num_feas):\n",
    "\n",
    "    '''\n",
    "    Returns a list of tuples (node name=str, node_feas=np array of features)\n",
    "    '''\n",
    "    \n",
    "    featname_file = node_file.replace('.feat', '.featnames')\n",
    "\n",
    "    with open(node_file) as opened_node:\n",
    "        node_file_lines = opened_node.readlines()\n",
    "    \n",
    "    with open(featname_file) as opened_featname:\n",
    "        featname_file_lines = opened_featname.readlines()\n",
    "\n",
    "    node_list = []\n",
    "    for line in node_file_lines:\n",
    "        split_line = line.split()\n",
    "        if len(split_line[1:]) != len(featname_file_lines):\n",
    "            print('error: features recorded not equal features expected')\n",
    "        node_name = int(split_line[0])\n",
    "        node_feas = -np.ones(num_feas)\n",
    "        for i in range(len(split_line[1:])):\n",
    "            split_featname_line = featname_file_lines[i].split()\n",
    "            fea_index = int(split_featname_line[3].strip())\n",
    "            node_feas[fea_index] = split_line[i + 1]\n",
    "        current_node = (node_name, node_feas)\n",
    "        node_list.append(current_node)\n",
    "            \n",
    "    return node_list\n",
    "\n",
    "def read_ego_nodes(node_file, num_feas):\n",
    "\n",
    "    '''\n",
    "    Returns a list of tuples (node name=str, node_feas=np array of features)\n",
    "    '''\n",
    "    \n",
    "    featname_file = node_file.replace('.egofeat', '.featnames')\n",
    "    \n",
    "    with open(node_file) as opened_node:\n",
    "        node_file_lines = opened_node.readlines()\n",
    "        \n",
    "    with open(featname_file) as opened_featname:\n",
    "        featname_file_lines = opened_featname.readlines()\n",
    "\n",
    "    node_list = []\n",
    "    for line in node_file_lines:\n",
    "            split_line = line.split() \n",
    "            node_feas = -np.ones(num_feas)\n",
    "            node_name = ''\n",
    "            for s in node_file:\n",
    "                if s.isdigit():\n",
    "                    node_name += s\n",
    "            node_name = int(node_name)\n",
    "            for i in range(len(split_line)):\n",
    "                split_featname_line = featname_file_lines[i].split()\n",
    "                fea_index = int(split_featname_line[3])\n",
    "                node_feas[fea_index] = split_line[i]\n",
    "            current_node = (node_name, node_feas)\n",
    "            node_list.append(current_node)\n",
    "            \n",
    "    return node_list\n",
    "\n",
    "def read_edges(edge_file):\n",
    "\n",
    "    '''\n",
    "    Returns a list of edges (node1=int, node2=int)\n",
    "    '''\n",
    "    with open(edge_file) as opened_edge:\n",
    "        edge_file_lines = opened_edge.readlines()\n",
    "    \n",
    "    edge_list = []\n",
    "    for line in edge_file_lines:\n",
    "            split_line = line.split()\n",
    "            edge_list.append((int(split_line[0]), int(split_line[1])))\n",
    "            \n",
    "    return edge_list\n",
    "\n",
    "def read_featnames(featname_file):\n",
    "    '''\n",
    "    Returns a list of feature ID's which are strings\n",
    "    '''\n",
    "    with open(featname_file) as opened_featname:\n",
    "        featname_file_lines = opened_featname.readlines()\n",
    "\n",
    "    featname_list = []\n",
    "    for line in featname_file_lines:\n",
    "            split_line = line.split()  \n",
    "            featname_list.append(split_line[3].strip())\n",
    "            \n",
    "    return featname_list\n",
    "\n",
    "def get_num_feas(featname_dir):\n",
    "    full_featname_list = []\n",
    "    for file in os.listdir(featname_dir):\n",
    "        if file.endswith('.featnames'):\n",
    "            featnames = read_featnames(featname_dir+file)\n",
    "            full_featname_list += featnames\n",
    "        \n",
    "    return len(set(full_featname_list))\n",
    "\n",
    "def create_data_files(data_dir):\n",
    "    '''\n",
    "    creates a feature array and edge array from the data files in datadir.\n",
    "    graph type options are 'normal', 'directed'\n",
    "    '''\n",
    "        \n",
    "    num_feas = get_num_feas(data_dir)\n",
    "    nodes_list = []\n",
    "    edges_list = []\n",
    "    \n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.feat'):\n",
    "            nodes = read_nodes(data_dir+file, num_feas)\n",
    "            nodes_list += nodes\n",
    "        elif file.endswith('.egofeat'):\n",
    "            nodes = read_ego_nodes(data_dir+file, num_feas)\n",
    "            nodes_list += nodes\n",
    "        elif file.endswith('combined.txt'):\n",
    "            edges = read_edges(data_dir+file)\n",
    "            edges_list += edges \n",
    "            \n",
    "    sorted_list = sorted(nodes_list, key=itemgetter(0))\n",
    "    \n",
    "    '''\n",
    "    Testing if duplicate id feature vectors are identical\n",
    "    '''\n",
    "#     prev_id = None\n",
    "#     prev_features = None\n",
    "#     for item in sorted_list:\n",
    "#         if prev_id == item[0]:\n",
    "#             if np.array_equal(prev_features, item[1]) == False:\n",
    "#                 print('error')\n",
    "# #                 print(prev_features)\n",
    "# #                 print(item[1])\n",
    "#             if np.array_equal(prev_features, item[1]):\n",
    "#                 print('hooray')\n",
    "#         prev_id = item[0]\n",
    "#         prev_features = item[1]\n",
    "    \n",
    "    nodes_list = sorted(OrderedDict(nodes_list).items(), key=itemgetter(0))\n",
    "    edges_list = sorted(edges_list, key=itemgetter(0))\n",
    "    num_samples = len(nodes_list)\n",
    "    feature_array = np.zeros((num_samples + 1, num_feas + 1))\n",
    "    feature_array[0, 1:] = range(num_feas)\n",
    "    feature_array[1:, 1:] = np.vstack(np.array(nodes_list)[:, 1])\n",
    "    feature_array[1:, 0] = np.array(nodes_list)[:, 0]\n",
    "    np.savetxt('node_features.csv', feature_array, fmt='%i', delimiter=\",\")\n",
    "    np.savetxt('graph.txt', np.array(edges_list), fmt='%i', delimiter=' ')\n",
    "    \n",
    "create_data_files('facebook_data/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
